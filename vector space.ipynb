{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import Normalizer, word_tokenize, Stemmer, Lemmatizer\n",
    "import itertools, collections\n",
    "import math, heapq\n",
    "import pandas as pd\n",
    "import pickle,json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "N_documents = 12201\n",
    "tokens = []\n",
    "total_tf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_punctuation(text):\n",
    "    stop_words = []\n",
    "    with open (r'stopwords.txt', 'r', encoding='utf_8') as file: \n",
    "        stop_words = file.read().splitlines()\n",
    "        \n",
    "    removed = []\n",
    "    for t in text:\n",
    "        flg = False\n",
    "        for s in stop_words:\n",
    "            if t == s:\n",
    "                flg = True\n",
    "                break\n",
    "        if not flg:\n",
    "            removed.append(t)\n",
    "    return removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def process(self, text):\n",
    "        normalized_content = normalizer.normalize(text=text)\n",
    "        terms = word_tokenize(normalized_content)\n",
    "        clear_content = check_punctuation(terms)\n",
    "        stemmed_terms = []\n",
    "        for t in clear_content:\n",
    "                stemmed_terms.append(stemmer.stem(t))\n",
    "        return stemmed_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(r'IR_data.json')\n",
    "pre_processor = PreProcessor()\n",
    "\n",
    "inverted_index_with_frequency = defaultdict(list)\n",
    "print('hi')\n",
    "for i in range (0, N_documents):\n",
    "        content = data[i]['content']\n",
    "        stemmed_terms = pre_processor.process(content)\n",
    "        in_doc_tokens = []\n",
    "        in_doc_tf = {}\n",
    "        for t in stemmed_terms:\n",
    "                in_doc_tokens.append({'term': t, 'docID': i})\n",
    "                in_doc_tf[t] = in_doc_tf.get(t,0) + 1\n",
    "        tokens.extend(in_doc_tokens)\n",
    "\n",
    "        # As said before instead of vector we record weight of each term in doc\n",
    "        total_tf[i] = collections.OrderedDict(sorted(in_doc_tf.items()))\n",
    "        for t in total_tf[i]:\n",
    "                inverted_index_with_frequency[t].append({i:in_doc_tf[t]})\n",
    "\n",
    "##print(dictonary['آسیا'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = collections.defaultdict(list)\n",
    "for token in tokens:\n",
    "    values = inverted_index.get(token['term'],[])\n",
    "    if token['docID'] not in values:\n",
    "        values.append(token['docID'])\n",
    "    inverted_index[token['term']] = values   \n",
    "##inverted_index = collections.OrderedDict(sorted(inverted_index.items()))\n",
    "  \n",
    "\n",
    "\n",
    "stop_words = []\n",
    "for term in inverted_index.keys():\n",
    "    if len(inverted_index[term]) > 0.3 * N_documents:\n",
    "        stop_words.append(term)\n",
    "for s in stop_words:\n",
    "    inverted_index.pop(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idf\n",
    "idf = {}\n",
    "for term in inverted_index:\n",
    "    nf = len(inverted_index[term])\n",
    "    idf[term] = math.log(N_documents / nf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['مرد', 'سالار']\n",
      "{'مرد': 1, 'سالار': 1}\n"
     ]
    }
   ],
   "source": [
    "## Query Vectorize and Index Elimination\n",
    "pre_processor = PreProcessor()\n",
    "\n",
    "# with open (\"inverted_index.json\", \"w\") as f:\n",
    "# json.dump(inverted_index,f)\n",
    "\n",
    "query = input(\"Enter Yout Query: \")\n",
    "splited_query = pre_processor.process(query)\n",
    "print(splited_query)\n",
    "\n",
    "term_freq = dict(collections.Counter(splited_query))\n",
    "print(term_freq)\n",
    "query_term_tf = {}\n",
    "for term, freq in term_freq.items():\n",
    "        if term in inverted_index.keys():\n",
    "            query_term_tf[term] = 1+math.log(freq,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6092741724045876\n",
      "1.4771212547196624\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(idf['فایزر'])\n",
    "for doc, doc_tf in total_tf.items():\n",
    "        for d_term in doc_tf.keys():\n",
    "            if d_term == \"فایزر\":\n",
    "                if doc_tf[d_term] > 0:\n",
    "                    # print('Found {} in doc {}'.format(d_term, doc))\n",
    "                    print(1+math.log(doc_tf[d_term], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "3.0207170161180046\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "3.0207170161180046\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "3.276217075059749\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "3.0207170161180046\n",
      "2.660609908512887\n",
      "3.0207170161180046\n",
      "3.0207170161180046\n",
      "3.0207170161180046\n",
      "2.045002741966025\n",
      "3.4743983173851873\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "3.0207170161180046\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "3.276217075059749\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "3.0207170161180046\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "3.0207170161180046\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "3.276217075059749\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "2.045002741966025\n",
      "2.660609908512887\n",
      "2.045002741966025\n",
      "3.276217075059749\n",
      "2.045002741966025\n",
      "{277: 2.045002741966025, 278: 2.045002741966025, 403: 2.045002741966025, 679: 2.045002741966025, 732: 2.045002741966025, 785: 2.045002741966025, 800: 2.045002741966025, 974: 2.045002741966025, 1834: 2.660609908512887, 2880: 2.660609908512887, 3299: 2.045002741966025, 3446: 2.045002741966025, 3842: 2.660609908512887, 4140: 3.0207170161180046, 4243: 2.660609908512887, 4743: 2.045002741966025, 4828: 2.045002741966025, 4911: 2.045002741966025, 5036: 2.045002741966025, 6407: 2.045002741966025, 6650: 2.045002741966025, 6846: 2.660609908512887, 6881: 2.045002741966025, 7196: 2.045002741966025, 7217: 2.045002741966025, 7231: 2.045002741966025, 7433: 2.045002741966025, 7446: 3.0207170161180046, 7453: 2.045002741966025, 7669: 2.045002741966025, 7790: 2.045002741966025, 7806: 2.045002741966025, 7848: 2.045002741966025, 7849: 2.045002741966025, 7855: 2.045002741966025, 7890: 2.045002741966025, 8024: 2.045002741966025, 8048: 2.045002741966025, 8085: 2.660609908512887, 8162: 2.045002741966025, 8272: 2.660609908512887, 8281: 2.045002741966025, 8625: 2.045002741966025, 8852: 2.045002741966025, 8894: 2.660609908512887, 9051: 2.045002741966025, 9071: 2.045002741966025, 9074: 2.660609908512887, 9078: 3.276217075059749, 9110: 2.045002741966025, 9271: 2.045002741966025, 9291: 2.045002741966025, 9294: 2.045002741966025, 9384: 2.045002741966025, 9396: 2.045002741966025, 9403: 2.045002741966025, 9496: 2.660609908512887, 9535: 2.045002741966025, 9576: 2.045002741966025, 9671: 2.660609908512887, 9695: 2.045002741966025, 9712: 2.045002741966025, 9768: 2.045002741966025, 9837: 2.660609908512887, 9871: 2.045002741966025, 10011: 3.0207170161180046, 10049: 2.660609908512887, 10116: 3.0207170161180046, 10153: 3.0207170161180046, 10285: 3.0207170161180046, 10286: 2.045002741966025, 10287: 3.4743983173851873, 10295: 2.660609908512887, 10313: 2.045002741966025, 10418: 3.0207170161180046, 10428: 2.660609908512887, 10473: 2.045002741966025, 10492: 2.660609908512887, 10651: 2.045002741966025, 10659: 2.045002741966025, 10756: 3.276217075059749, 10759: 2.660609908512887, 10790: 2.045002741966025, 10801: 2.045002741966025, 10819: 2.045002741966025, 10844: 2.045002741966025, 10870: 2.045002741966025, 10900: 2.660609908512887, 11070: 3.0207170161180046, 11075: 2.660609908512887, 11078: 2.045002741966025, 11090: 2.045002741966025, 11099: 2.045002741966025, 11118: 2.045002741966025, 11182: 2.045002741966025, 11256: 2.045002741966025, 11324: 2.660609908512887, 11330: 2.045002741966025, 11405: 3.0207170161180046, 11519: 2.045002741966025, 11525: 2.045002741966025, 11802: 2.660609908512887, 11857: 3.276217075059749, 11878: 2.660609908512887, 11912: 2.045002741966025, 11953: 2.045002741966025, 12048: 2.660609908512887, 12106: 2.045002741966025, 12109: 3.276217075059749, 12128: 2.045002741966025}\n"
     ]
    }
   ],
   "source": [
    "docs_score = {}\n",
    "for q_term, freq in query_term_tf.items():\n",
    "    for doc, doc_tf in total_tf.items():\n",
    "        for d_term in doc_tf.keys():\n",
    "            if  d_term == q_term:\n",
    "                # print('Found {} in doc {}'.format(d_term, doc))\n",
    "                wd = (1+math.log(doc_tf[d_term], 10))*(idf[d_term])\n",
    "                print(wd)\n",
    "                docs_score[doc] = docs_score.get(doc,0) + (freq * wd)\n",
    "print(docs_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_length(doc):\n",
    "    l = 0\n",
    "    for term, tf in total_tf[doc].items():\n",
    "        if term in inverted_index.keys():\n",
    "            l += (idf[term] * (1+math.log(tf, 10)))**2\n",
    "    return math.sqrt(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{277: 0.049955065159919446, 278: 0.06042465543361134, 403: 0.14061044399812067, 679: 0.08621501616734108, 732: 0.09196340240174954, 785: 0.10755734679457103, 800: 0.11611346586665122, 974: 0.04892965791374303, 1834: 0.15159696221522423, 2880: 0.14930526269689748, 3299: 0.22114561460081897, 3446: 0.06469894924483113, 3842: 0.16821457013847452, 4140: 0.11573685246960361, 4243: 0.14187261018023684, 4743: 0.04848078715061959, 4828: 0.062045273991535775, 4911: 0.07416751122023772, 5036: 0.183088536256268, 6407: 0.11698219220374903, 6650: 0.11991721228083979, 6846: 0.07017558628133105, 6881: 0.07482344989086251, 7196: 0.06079582478566409, 7217: 0.06686628942128109, 7231: 0.08078270531189279, 7433: 0.08496601057540604, 7446: 0.1805738325842435, 7453: 0.11369361824699643, 7669: 0.08703719356617398, 7790: 0.06913009805859237, 7806: 0.04939294541434891, 7848: 0.05568345791849261, 7849: 0.04852079521340419, 7855: 0.04365388880107347, 7890: 0.06128573518108366, 8024: 0.09304680111106435, 8048: 0.1520792343526807, 8085: 0.11333446435725002, 8162: 0.02965621471488883, 8272: 0.05185877604849335, 8281: 0.057261525355378574, 8625: 0.10091481684669198, 8852: 0.059857509779586426, 8894: 0.057862034508561935, 9051: 0.05494464293785588, 9071: 0.06769453749042897, 9074: 0.11086311173714536, 9078: 0.15886646831501225, 9110: 0.05130132206885261, 9271: 0.0557376184995996, 9291: 0.06363846113108164, 9294: 0.11589187390400137, 9384: 0.037629012515098356, 9396: 0.0577921314420933, 9403: 0.020799379983662304, 9496: 0.040014566886927505, 9535: 0.0835403370281703, 9576: 0.08978100788278515, 9671: 0.02250697520855915, 9695: 0.09394455525703095, 9712: 0.03640073192260789, 9768: 0.07689216595411642, 9837: 0.07881221991104467, 9871: 0.05394510478405475, 10011: 0.19488746942917765, 10049: 0.06993340601608385, 10116: 0.08372638611099671, 10153: 0.07694939806325454, 10285: 0.07152557512882358, 10286: 0.0526870512171421, 10287: 0.07229608960988863, 10295: 0.08447122922125609, 10313: 0.09297324927776264, 10418: 0.11527028511004084, 10428: 0.08274538435879214, 10473: 0.05723228701679614, 10492: 0.08548324636791853, 10651: 0.1486801085054167, 10659: 0.09188348046339385, 10756: 0.13701628295869947, 10759: 0.10015964110076703, 10790: 0.03894404993641814, 10801: 0.0632865188632799, 10819: 0.10015895764154076, 10844: 0.04239474752633823, 10870: 0.09722077954326871, 10900: 0.1675747676578349, 11070: 0.08031679137025485, 11075: 0.032954279218666865, 11078: 0.032404579114659944, 11090: 0.09642870768478788, 11099: 0.06041169903058518, 11118: 0.07857016596609127, 11182: 0.0814687502294699, 11256: 0.049621601744374105, 11324: 0.050683400957175745, 11330: 0.06873689740173025, 11405: 0.058791394674028614, 11519: 0.12387080319754272, 11525: 0.07505543872540531, 11802: 0.14403627495327448, 11857: 0.09155165894699596, 11878: 0.09448531372799254, 11912: 0.09126285417957207, 11953: 0.03138913308425353, 12048: 0.12252144726193494, 12106: 0.045493526487657365, 12109: 0.10599659635002327, 12128: 0.10559068614189601}\n"
     ]
    }
   ],
   "source": [
    "## Similarity\n",
    "for doc, score in docs_score.items():\n",
    "    docs_score[doc] = score/get_doc_length(doc=doc)\n",
    "\n",
    "print(docs_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3299, 0.22114561460081897), (10011, 0.19488746942917765), (5036, 0.183088536256268), (7446, 0.1805738325842435), (3842, 0.16821457013847452)]\n"
     ]
    }
   ],
   "source": [
    "# Return Top-K using heap method\n",
    "heap = [(-value, key) for key,value in docs_score.items()]\n",
    "largest = heapq.nsmallest(5, heap)\n",
    "top_k = [(y, -x) for x,y in largest]\n",
    "\n",
    "print(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "champion_list = {}\n",
    "for term in inverted_index_with_frequency.keys():\n",
    "    document = {}\n",
    "    for d in inverted_index_with_frequency[term]:\n",
    "        document.update(d)\n",
    "    sorted_ch = {k: v for k,v in sorted(document.items(), key=lambda item: item[1], reverse=True)}\n",
    "    sorted_ch = dict(itertools.islice((sorted_ch.items()), 100))\n",
    "    # print(sorted(sorted_result.items()))\n",
    "    champion_list[term] = collections.OrderedDict((sorted_ch.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'سالار': 1.0}\n",
      "5 10287\n",
      "4 9078\n",
      "4 10756\n",
      "4 11857\n",
      "4 12109\n",
      "3 4140\n",
      "3 7446\n",
      "3 10011\n",
      "3 10116\n",
      "3 10153\n",
      "3 10285\n",
      "3 10418\n",
      "3 11070\n",
      "3 11405\n",
      "2 1834\n",
      "2 2880\n",
      "2 3842\n",
      "2 4243\n",
      "2 6846\n",
      "2 8085\n",
      "2 8272\n",
      "2 8894\n",
      "2 9074\n",
      "2 9496\n",
      "2 9671\n",
      "2 9837\n",
      "2 10049\n",
      "2 10295\n",
      "2 10428\n",
      "2 10492\n",
      "2 10759\n",
      "2 10900\n",
      "2 11075\n",
      "2 11324\n",
      "2 11802\n",
      "2 11878\n",
      "2 12048\n",
      "1 277\n",
      "1 278\n",
      "1 403\n",
      "1 679\n",
      "1 732\n",
      "1 785\n",
      "1 800\n",
      "1 974\n",
      "1 3299\n",
      "1 3446\n",
      "1 4743\n",
      "1 4828\n",
      "1 4911\n",
      "1 5036\n",
      "1 6407\n",
      "1 6650\n",
      "1 6881\n",
      "1 7196\n",
      "1 7217\n",
      "1 7231\n",
      "1 7433\n",
      "1 7453\n",
      "1 7669\n",
      "1 7790\n",
      "1 7806\n",
      "1 7848\n",
      "1 7849\n",
      "1 7855\n",
      "1 7890\n",
      "1 8024\n",
      "1 8048\n",
      "1 8162\n",
      "1 8281\n",
      "1 8625\n",
      "1 8852\n",
      "1 9051\n",
      "1 9071\n",
      "1 9110\n",
      "1 9271\n",
      "1 9291\n",
      "1 9294\n",
      "1 9384\n",
      "1 9396\n",
      "1 9403\n",
      "1 9535\n",
      "1 9576\n",
      "1 9695\n",
      "1 9712\n",
      "1 9768\n",
      "1 9871\n",
      "1 10286\n",
      "1 10313\n",
      "1 10473\n",
      "1 10651\n",
      "1 10659\n",
      "1 10790\n",
      "1 10801\n",
      "1 10819\n",
      "1 10844\n",
      "1 10870\n",
      "1 11078\n",
      "1 11090\n",
      "1 11099\n",
      "[(3299, 0.22114561460081897), (10011, 0.19488746942917765), (5036, 0.183088536256268), (7446, 0.1805738325842435), (3842, 0.16821457013847452)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs_score_ch = {}\n",
    "print(query_term_tf)\n",
    "for q_term, q_freq in query_term_tf.items():\n",
    "    for doc, freq in champion_list[q_term].items():\n",
    "        print(freq, doc)\n",
    "        wd = (1+math.log(freq, 10))*(idf[q_term])\n",
    "        docs_score_ch[doc] = docs_score_ch.get(doc,0) + (q_freq * wd)\n",
    "\n",
    "for doc, score in docs_score_ch.items():\n",
    "    docs_score_ch[doc] = score/get_doc_length(doc=doc)\n",
    "\n",
    "heap = [(-value, key) for key,value in docs_score_ch.items()]\n",
    "largest = heapq.nsmallest(5, heap)\n",
    "top_k = [(y, -x) for x,y in largest]\n",
    "\n",
    "print(top_k)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
